CONTENTS OF THIS FILE
---------------------
* Introduction
* Usage
* Requirements and Configuration files
* Content
	- Parser Module
	- Builder Module
	- Generator Module
	- Collector Module


INTRODUCTION
------------
		Branch Hinting Tool is intended to extract GCOV statistics and build a 
	report of branching hints. It can be used for cross-checking the relevance
	of existing hints into the code and/or to propose hints for unhinted 
	branches. Runing time varies from project to project and workload used
	to collect statistics.A csv file will be obtained after runing this 
	profiling tool.
USAGE:
------
	Positional arguments:
  		filename        filename or path to folder( pass -z if folder is PHP
                        folder

	Optional arguments:
		-h, --help      show this help message and exit
  		-l [LOWER]            lower limmit acceptable limit for expected
  		-u [UPPER]            upper limmit acceptable limit for unexpected
  		-F                    apply on folder
  		-p                    parse and build
  		-r                    run the workload
  		-v                    verbose
  		-a                    returns output in csv format
  		-d [PATH]             PATH where we put the LCOV RESULTS
  		-i [PATH_TO_INI_FILE] ini file path

    Eg. python main.py ~/path/to/project -i branch_hints.ini -p -r


REQUIREMENTS AND CONFIGURATION FILES
------------
* gcc version 3.0 minimum (4.9 recommended)
* python-2.7 
* Makefile for targeted project
* clean working folder
* edit branch_hints.ini file

	- Makefile:
	User must have a generated makefile for his project. It must contain
	a target with "-fprofile-arcs -ftest-coverage" or "--coverage all"
	flags to build instrumented binaries used by gcov.
	Makefile also must contain a clean rule called each time after tool
	ends it's execution.

	- branch_hints.ini:
	This file is structured in the following way:
	[Environment]
	WORKING_FOLDER=/your/project/build/folder
	#this folder must be empty because all your project files will be 
	#copied here(an EnvironmentError will be thrown if not)
	PREPARE_SCRIPT=script.sh
	#prepare script is used to configure the project pre-build. In this
	#script user will set his pre-requirements such as: ./configure or
	#./build
	[Makefile]
	RULE=make prof-gen -j8
	CLEAN=make clean
	[Config]
	BLACKLIST=blacklist.cfg
	#in this file you tell what files should be ignored by parser
	COMMAND=./your_exe /workload/used
	LIBS=/folder/libs
	#by default each lib and .gcno is placed in the same folder with
	#source/header but you can specify custom lib folders for your 
	#project when building. If you left libs folder as default when
	#you compiled, leave this field blank(eg "LIBS =")

	- blacklist.cfg:
	This file is used to tell what source file or header should be
	ignored by parser. You should list here(one by line) all the
	files that aren't relevant for this profiling tool to save time
	used for parsing(eg. headers used for network configuration,
	extensions used by your project etc.)


CONTENT
-------

+---------+     +---------+     +-----------+     +-----------+      xxxxxxxxxxxxx                                 
|1.PARSER +---->+2.BUILDER+---->+3.GENERATOR+---->+4.COLLECTOR+----> x STATS.CSV x                       
+---------+     +---------+     +-----------+     +-----------+      xxxxxxxxxxxxx                     â€‰

	1. Parser: It's implementation and functions are described in 
	branch_tagger/README.
		Files used to implement this module: branch_tagger/*

	2. Builder: this section copies your project into workspace and
	builds it using the rules configured in .ini file. An instrumented
	binary/binaries is/are obtained and all binaries are run on given
	workload (eg. PHP project is build with make prof-gen -j8 and run
	on WordPress's index.php). A .gcno and .gcda file is obtained for 
	each source and header.
		Files used to implement this module: autogen.py, instrument.py

	3. Generator: All files generated by builder are used in this stage
	to generate .gcov and .csv file. First a GCOV folder will be created
	inside your workspace directory and the project's folder hierarchy 
	will be recreated inside GCOV; for each source, a folder is creaded
	(in this way we want to prevent header gcov files overwrite. When
	same header is called in two different sources located in the same
	directory, only the statistics obtained from last file analyzed with
	gcov will remain and the other occurences of this header will be 
	overwritten).
	.gcda and .gcno files are used to obtain .gcov files. All gcov
	files obtained from one source will be placed in his GCOV respective 
	directory.
	All .gcov files will be parsed and a .csv file with relevant 
	information will be generated for each source and header.
		Files used to implement this module: generate_gcov.py,
		generate_csv.py

	4. Collector: In first phase, all .csv files obtained from same header
	are summed up and a global .csv file for that header will be generated.
	In second phase, all .csv files obtained from sources and headers in
	this project are put together in a hash map. In this stage hints are
	analyzed and correct hints, based on % branch taken, are generated.
		Files used to implement this module: collect_statistics.py,
		calculs.py, sum_csvs.py

	Other files used in this project: ini.py, blacklist.py, constants.py


	STATS.CSV file format:
	Path, Filename, Line, State, Current_hint, Expected_hint, Total #, \
	Taken %, Taken #, Not Taken #, Num_Branches, Branch_Type, Line_of_code

